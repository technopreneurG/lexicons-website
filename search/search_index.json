{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Lexicon A lexicon is the vocabulary of a person, language, or branch of knowledge (such as nautical or medical). In linguistics, a lexicon is a language's inventory of lexemes. The word \"lexicon\" derives from the Greek \u03bb\u03b5\u03be\u03b9\u03ba\u03cc\u03bd (lexicon), neuter of \u03bb\u03b5\u03be\u03b9\u03ba\u03cc\u03c2 (lexikos) meaning \"of or for words.\" futher reading: https://en.wikipedia.org/wiki/Lexicon Inspiration: Long long ago there used to be a Y!Lexicon page on Yahoo! interanets, it was very useful for new hires to get introduced to various terminologies used inside Yahoo!. The awesome lists , a great way of organising knowledge. List of Lexicons: Computational linguistics Artificial neural networks Cloud Computing","title":"Home"},{"location":"lexicon-artificial-neural-networks/","text":"ANN (Artificial neural networks) Artificial neural networks are computational models inspired by biological neural networks, and are used to approximate functions that are generally unknown. Particularly, they are inspired by the behaviour of neurons and the electrical signals they convey between input (such as from the eyes or nerve endings in the hand), processing, and output from the brain (such as reacting to light, touch, or heat). https://en.wikipedia.org/wiki/Artificial_neural_network BP (Backpropagation) Backpropagation is a method used in artificial neural networks to calculate a gradient that is needed in the calculation of the weights to be used in the network. Backpropagation is shorthand for \"the backward propagation of errors,\" since an error is computed at the output and distributed backwards throughout the network\u2019s layers. It is commonly used to train deep neural networks. https://en.wikipedia.org/wiki/Backpropagation Tags: Algorithms, Artificial Neural Networks Feedforward neural network In this network the information moves in only one direction-forward, From the input nodes data goes through the hidden nodes (if any) and to the output nodes. There are no cycles or loops in the network. Feedforward networks can be constructed from different types of units, e.g. binary McCulloch-Pitts neurons, the simplest example being the perceptron. Continuous neurons, frequently with sigmoidal activation, are used in the context of backpropagation of error. https://en.wikipedia.org/wiki/Feedforward_neural_network Perceptron Invented in 1957 by Frank Rosenblatt at the Cornell Aeronautical Laboratory, a perceptron is the simplest neural network possible a computational model of a single neuron. A perceptron consists of one or more inputs, a processor, and a single output. A perceptron follows the \"feed-forward\" model, meaning inputs are sent into the neuron, are processed, and result in an output. http://natureofcode.com/book/chapter-10-neural-networks/ Tags: Classification Algorithms, Machine Learning, Artificial Neural Networks SGD (Stochastic gradient descent) Stochastic gradient descent (often shortened in SGD), also known as incremental gradient descent, is a stochastic approximation of the gradient descent optimization method for minimizing an objective function that is written as a sum of differentiable functions. In other words, SGD tries to find minima or maxima by iteration. https://en.wikipedia.org/wiki/Stochastic_gradient_descent http://ufldl.stanford.edu/tutorial/supervised/OptimizationStochasticGradientDescent/ Tags: Algorithms, Computational Statistics","title":"Artificial Neural Networks"},{"location":"lexicon-artificial-neural-networks/#ann","text":"(Artificial neural networks) Artificial neural networks are computational models inspired by biological neural networks, and are used to approximate functions that are generally unknown. Particularly, they are inspired by the behaviour of neurons and the electrical signals they convey between input (such as from the eyes or nerve endings in the hand), processing, and output from the brain (such as reacting to light, touch, or heat). https://en.wikipedia.org/wiki/Artificial_neural_network","title":"ANN"},{"location":"lexicon-artificial-neural-networks/#bp","text":"(Backpropagation) Backpropagation is a method used in artificial neural networks to calculate a gradient that is needed in the calculation of the weights to be used in the network. Backpropagation is shorthand for \"the backward propagation of errors,\" since an error is computed at the output and distributed backwards throughout the network\u2019s layers. It is commonly used to train deep neural networks. https://en.wikipedia.org/wiki/Backpropagation Tags: Algorithms, Artificial Neural Networks","title":"BP"},{"location":"lexicon-artificial-neural-networks/#feedforward-neural-network","text":"In this network the information moves in only one direction-forward, From the input nodes data goes through the hidden nodes (if any) and to the output nodes. There are no cycles or loops in the network. Feedforward networks can be constructed from different types of units, e.g. binary McCulloch-Pitts neurons, the simplest example being the perceptron. Continuous neurons, frequently with sigmoidal activation, are used in the context of backpropagation of error. https://en.wikipedia.org/wiki/Feedforward_neural_network","title":"Feedforward neural network"},{"location":"lexicon-artificial-neural-networks/#perceptron","text":"Invented in 1957 by Frank Rosenblatt at the Cornell Aeronautical Laboratory, a perceptron is the simplest neural network possible a computational model of a single neuron. A perceptron consists of one or more inputs, a processor, and a single output. A perceptron follows the \"feed-forward\" model, meaning inputs are sent into the neuron, are processed, and result in an output. http://natureofcode.com/book/chapter-10-neural-networks/ Tags: Classification Algorithms, Machine Learning, Artificial Neural Networks","title":"Perceptron"},{"location":"lexicon-artificial-neural-networks/#sgd","text":"(Stochastic gradient descent) Stochastic gradient descent (often shortened in SGD), also known as incremental gradient descent, is a stochastic approximation of the gradient descent optimization method for minimizing an objective function that is written as a sum of differentiable functions. In other words, SGD tries to find minima or maxima by iteration. https://en.wikipedia.org/wiki/Stochastic_gradient_descent http://ufldl.stanford.edu/tutorial/supervised/OptimizationStochasticGradientDescent/ Tags: Algorithms, Computational Statistics","title":"SGD"},{"location":"lexicon-cloud-computing/","text":"Cloud Computing Cloud computing is a form of Internet-based computing that provides shared computer processing resources and data to computers and other devices on demand. It is a model for enabling ubiquitous, on-demand access to a shared pool of configurable computing resources (e.g., computer networks, servers, storage, applications and services), which can be rapidly provisioned and released with minimal management effort. https://en.wikipedia.org/wiki/Cloud_computing","title":"Cloud Computing"},{"location":"lexicon-cloud-computing/#cloud-computing","text":"Cloud computing is a form of Internet-based computing that provides shared computer processing resources and data to computers and other devices on demand. It is a model for enabling ubiquitous, on-demand access to a shared pool of configurable computing resources (e.g., computer networks, servers, storage, applications and services), which can be rapidly provisioned and released with minimal management effort. https://en.wikipedia.org/wiki/Cloud_computing","title":"Cloud Computing"},{"location":"lexicon-computational-linguistics/","text":"NLP (Natural language processing) Natural language processing (NLP) is a field of computer science, artificial intelligence and computational linguistics concerned with the interactions between computers and human (natural) languages, and, in particular, concerned with programming computers to fruitfully process large natural language corpora. https://en.wikipedia.org/wiki/Natural_language_processing NLP (Natural language programming) Natural Language Programming (NLP) is an ontology-assisted way of programming in terms of natural language sentences, e.g. English. A structured document with Content, sections and subsections for explanations of sentences forms a NLP document, which is actually a computer program. https://en.wikipedia.org/wiki/Natural_language_programming","title":"Computational Linguistics"},{"location":"lexicon-computational-linguistics/#nlp","text":"(Natural language processing) Natural language processing (NLP) is a field of computer science, artificial intelligence and computational linguistics concerned with the interactions between computers and human (natural) languages, and, in particular, concerned with programming computers to fruitfully process large natural language corpora. https://en.wikipedia.org/wiki/Natural_language_processing","title":"NLP"},{"location":"lexicon-computational-linguistics/#nlp_1","text":"(Natural language programming) Natural Language Programming (NLP) is an ontology-assisted way of programming in terms of natural language sentences, e.g. English. A structured document with Content, sections and subsections for explanations of sentences forms a NLP document, which is actually a computer program. https://en.wikipedia.org/wiki/Natural_language_programming","title":"NLP"}]}